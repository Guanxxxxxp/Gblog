---
title: 赤裸裸的统计学
author:
  - 霄鹏
date: '2022-12-03'
slug: naked-statistics
categories:
  - 科普
tags:
  - 科普
  - 统计
lastmod: '2022-12-03T16:19:41+08:00'
keywords:
  - word 1
  - word 2
description: ''
summary: ''
weight: ~
draft: no
comments: yes
showToc: yes
TocOpen: yes
autonumbering: yes
hidemeta: no
disableShare: yes
searchHidden: no
showbreadcrumbs: yes
mermaid: yes
cover:
  image: ''
  caption: ''
  alt: ''
  relative: no
---

# 一章 统计学是大数据时代最炙手可热的学问

# 二章 描述统计学

描述任务的第一步通常是估量某套数据的“中间位置”，也就是统计学家所说的“集中趋势”。对于数据分布的“中间位置”，最基本的估量方法就是求平均数

其实所谓的平均数、平均值在这里是有一些问题的，即它们容易受到远离中心区域的“异常值”的干扰而出现失真

如果一组数据分布中没有特别离谱的异常值，那么它们的中位数和平均数将会是差不多的

标准差也是一个能够帮助我们在一大堆杂乱无章的数字中发现真理的统计数值，我们用它来衡量数据相对于平均值的分散程度

统计学里最重要、最有用、最常见的分布之一：正态分布。数据的分布一般来说都是对称的，以平均数为中轴呈现类似于“钟”的形状

百分差和百分率是不同的，百分差是指幅度，百分率是指具体比率

# 三章 统计数字会撒谎

虽然统计学是扎根于数学土壤里的，而且数学又是一门以准确著称的学科，但使用统计学来描述复杂现象的这一过程并不是精确无误的，这就为掩盖真相创造了大量的空间

首先，我们应该弄明白“精确”和“准确”这两个词之间至关重要的区别。这两个词不可以相互替代。“精确”反映的是我们描述事物的精度，如果一个答案是准确的，那么在这个基础上当然是越精确越好；但如果答案从一开始就是不准确的，那么再精确也毫无意义

即使是最为精确的计算或测量都应该检查一下是否符合常识

对优质数据的合理分析能够有效地调和对立的观点

关政府官员指出，在这项政策推行之后，将会有9200万美国人享受减税待遇，人均减税额超过1000 美元（具体数字应该是1083美元）。是不是会有9200万美国人将享受减税待遇？答案是肯定的。那么，这些人中的大部分人都可以少缴纳约1000美元的税款吗？不是的。因为减税额的中位数还不足100美元。只有数量相对少的巨富们才有资格享受大额减税，而正是这些人拉高了平均值。中位数对异常值并不敏感，因此在这个例子中，如果要看小布什政府的减税政策对普通家庭的影响，中位数可能会是一个更为准确的描述性数据

随着时间的推移，通货膨胀会逐渐削弱最低工资的购买力（以及其他名义工资的购买力，这也是为什么工会代表在与雇主谈判时总会谈到“生活成本调整”的问题）。如果商品价格的上涨速度快于美国国会调高最低工资的速度，那么每小时能够获得的最低工资的实际价值就会缩水

# 四章 相关性与相关系数

相关性作为一个统计工具的魅力就在于将两个变量的关联精炼成一个描述性数据：相关系数

相关系数拥有两个无与伦比的优势。
第一个优势体现在数学表达上，从本章后面的内容中我们能够发现，相关系数是一个区间为-1到1的常数。如果相关系数为1，即完全相关，表示一个变量的任何改变都会导致另一个变量朝着相同方向发生等量的改变。如果相关系数为1，即完全负相关，代表一个变量的任何变化都将会引发另一个变量朝着相反方向发生等量的改变。相关系数越接近1或-1，变量间的关联性就越强。如果相关系数为零（或者接近零），则意味着变量之间不存在有意义的联系，就比如一个人的鞋码和高考成绩之间的关系。
第二个吸引人的优势在于，相关系数不受变量单位的限制。我们可以计算身高和体重之间的关联性，哪怕身高和体重的单位分别是英寸和磅。我们甚至还可以计算出高中生家里的电视机数量和他们的考试成绩之间的关联性，而且我敢保证是正相关（之后的内容中我会给出解释）。这就是相关系数能够为我们完成的一件非常神奇的事情：将大量芜杂无序、单位不统一的复杂数据（就比如上面的身高、体重散点分布）加工成一个简洁、优雅的描述性数据。

1.将每个学生的身高转换为标准值：（身高-平均身高）/标准差。2.将每个学生的体重转换为标准值：（体重-平均身高）/标准差。3.将每个学生的体重标准值和身高标准值相乘，你会发现，当一个学生的身高和体重都偏离平均值较远时，乘积的绝对值也会较大。4.将第三步求得的乘积相加，再除以统计对象的数量（在这个例子中为15），就可以得到相关系数。

# 五章 概率与期望值

如果我们将每一个回报额乘以概率，再将得到的结果相加，就可以算出这一投资机会的期望值

# 六章 蒙提·霍尔悖论

每一期节目播到最后，总会有一个参赛者脱颖而出，站在主持人蒙提·霍尔旁边，在他们的眼前有3扇巨大的门，编号分别为1、2、3。蒙提会告知参赛者，其中的一扇门的门后摆放着极为诱人的大奖（比如说一辆小轿车），而另外两扇门的后面各站着一头羊，参赛者需要在这3扇门中选择一扇门，并获得那扇门后面的奖品。（如果有参赛者选中了羊，我怀疑他们是不是真的会把那头羊牵回家，因为在普通人看来，绝大多数参赛者都希望能开一辆新车回去。）
游戏刚开始时，中大奖的概率一目了然，两头羊和一辆车，参赛者有1/3的概率选中那扇后面是轿车的大门。但正如之前提到的，这个节目及其主持人蒙提·霍尔之所以能够在美国概率学课本中占得一席之地，是因为这个节目还有一个精心的安排。当参赛者选择了一扇门之后，蒙提会打开剩下的两扇门中的一扇，向观众和选手展示这扇门后面的奖品—一头羊，然后蒙提会再次询问参赛者是否要改变当初的选择，也就是在最初选择的那扇门和剩下的那扇门中再选择一次。

为了让表述更加清楚，我们假设参赛者最初选择的是1号门，蒙提随后打开了3号门，发现门后站着一头活羊。此时，场上还有两扇门是关着的，1号门和2号门，如果小轿车藏在1号门的后面，那么参赛者就中奖了，如果小轿车藏在2号门的后面，参赛者就会与大奖失之交臂。但就在这个时候，蒙提并不急于揭晓答案，而是再次询问参赛者是否坚持原来的选择，如果参赛者改变主意了，就相当于放弃了一开始选的1号门，而改选2号门。记住，这两扇门此时依旧紧闭着。参赛者唯一得到的新信息是，在自己刚刚没有选择的那两扇门中，至少有一扇门的后面是一头羊。
参赛者应不应该改变最初的选择？
答案是肯定的。如果参赛者坚持最初的选择，那么中大奖的概率为1/3；如果改选剩下的那扇门，那么中奖的概率就是2/3。如果你不相信的话，请往下读。

问题的关键就在于，主持人蒙提·霍尔本人是知道每一扇门背后的奖品的。如果参赛者选择了1号门，而且恰好小轿车就在这扇门的门后，那么蒙提就可以在2号或3号门中随便选一扇门打开，向观众展示一头羊。
如果参赛者选择了1号门，而小轿车停在2号门后，那么蒙提就会打开3号门。
如果参赛者选择了1号门，而小轿车停在3号门后，那么蒙提就会打开2号门。
通过改变之前的选择，参赛者就能从两次选择中获益，好处自然要比一次选择多。为了说服大家，我会用3种不同的方法来证明这一分析的正确性。

在这个过程中，蒙提还告诉了你另外两扇门中哪一扇门后面没有大奖，因此在如下的两种情况中你中大奖的概率是相同的：
1.先选择1号门，然后在任何一扇门打开之前同意换成2号和3号门。2.先选择1号门，然后在蒙提打开有羊的3号门之后同意换成2号门（或者在蒙提打开有羊的2号门之后同意换成3号门）。
在这两种情况下，通过改变选择，你中奖的概率都由原来的一扇门增加到两扇门，因此你的赢面也从1/3上涨为2/3。

我的第三种解释更像是第二种解释的极端版。假设摆在你面前的不是3扇门，而是100扇门。当你选择其中一扇门（比如说47号门）之后，蒙提·霍尔在剩下的99扇门中打开了98扇有羊的门，此时就剩两扇门没有打开了，一扇是你最初选择的47号门，一扇是蒙提剩下的（比如说61号门），你要换吗？
绝对要换！小轿车有99%的概率藏在你没有选的那99扇门的后面，而蒙提还好心地为你打开了其中的98扇门，他知道这98扇门的后面都没有小轿车。也就是说，如果你坚持最初的选择（47号门），那么你开着小轿车回家的概率仅为1%，牵一头羊回家的概率却高达99%；如果你的最初选择是错误的，那么小轿车就肯定藏在另外一扇门后面（61号门），如果你想中大奖，那就应该将最初的47号门换成最后剩下的61号门。

# 七章 黑天鹅事件

那时候，整个美国金融行业使用的都是同一个风险晴雨表—风险价值（VaR）模型。理论上说，VaR既是一个简洁的指标（将大量信息整合为一个单独的数字），又有强大的概率学支撑（对每家公司的资产和交易头寸都给出了预期收益和损失值），是一个不可多得的投资工具

这项投资在99%的情况下会使公司的损失低于1300万美元，但还有1%的概率造成重大损失

VaR最吸引人的地方，也是其最大的卖点就在于将风险描述为一个单一的数字—一个美元数据，仅此而已，而那些恰好不擅长数量分析的人就会趋之若鹜

很少有人会关注“尾部风险”（位于分布曲线末尾的小概率事件），以及这些小概率风险所带来的灾难性后果

乔·诺切拉总结了《黑天鹅：如何应对不可预知的未来》[1]
一书的作者，同时也是VaR模型的强烈反对者纳西姆·塔勒布的观点：“最大的风险从来就不是那些你能看得见、算得出的，而是那些你看不见从而无从估量的，那些看上去似乎远不在正常概率范围内、远远超出你的想象、你认为一辈子都不可能发生的风险，事实上，它们的确会发生，而且比你所能想到的要频繁得多。”

本章接下来将会介绍一些最为常见的与概率有关的错误、误解和道德困境。

想当然地认为事件之间不存在联系

对两个事件的统计独立一无所知

人们对于随机性的直观感受与概率的相关定律之间存在着鸿沟

成群病例的发生

群病例同样有可能只是单纯的巧合，不管发生的概率有多低

检方谬误

回归平均数（或趋均数回归）

在统计学上更加说得过去的解释是，能上杂志封面的通常都是那些近期表现尤为出色的运动员或队伍，如20连胜之类的异乎寻常的竞技表现，而他们之后的比赛成绩只不过是回归正常水平，这一现象就叫作回归平均数

统计性歧视

# 八章 数据与偏见

数据对于统计学家来说，就像是一个组织有效的进攻锋线面对一个明星四分卫。每一位明星四分卫前面都会站着一群优秀的阻挡队员，虽然他们默默无闻，但没有他们，我们就不会欣赏到四分卫的风采

一般来说，我们会要求数据做3件事。

第一，在评价某一大数据构成的人口特点时，我们可能会用到一个具有代表性的数据样本。统计学最强大的一点就在于，由一个在合理范围内足够大，并且正确抽取的样本推导出来的结论，能够准确地反映整个人口的特点，做到与对全体人口进行普查得到的结果分毫不差。

收集一个人口构成的代表性样本，最便捷的方式就是随机挑选子集（这就是大名鼎鼎的简单随机抽样法）。

（1）没有比代表性样本更有用的统计学工具了，统计学要是离了它，马上会黯然失色；（2）获得一个好样本比想象得难；（3）那些耸人听闻的夸张结论，其中有许多都是由于正确的统计方法被应用在了糟糕的样本上，但如果一开始统计方法就是错的，不管样本质量如何，都不会得到应有的结论；（4）样本容量很重要，而且容量越大越好

我们经常会要求数据做的第二件事是提供比较

在自然科学和生物科学领域，处理组和控制组的设计都相对直接。在以人为研究对象的实验过程中，一个反复出现的挑战就是如何让控制组和处理组之间只存在一个不同的条件。为此，这类实验所遵循的一条“金科玉律”就是随机取样，即实验对象（可以是人，也可以是学校、医院或任何东西）被随机分配到处理组或控制组。

我们收集数据的第三个原因，用我那处于青春期的女儿的话来说，就是“因为所以，科学道理”。有些时候我们面对信息时并没有一个明确的想法，但我们觉得总有一天这些数据会派上用场。

所谓纵向研究，就是对大量调查对象一生中不同时间点的信息进行收集，比如每两年进行一次采访。这类研究的参与者们会在长达10年、20年甚至50年的时间里接受定期采访，积累下极为丰富的连续性信息。

偏见

- 选择性偏见
    - 一个不合格的样本（宝琳的自由派朋友圈）会对整个人口（全美国的选民）产生一个误导性的简单印象。这就引出了一个我们应该时常问自己的问题：在给出评价之前，我们是如何选择样本的？如果人口中的每一个人被选入样本的概率不是均等的，那么由这样一个样本推导出的结论就会存在问题
- 发表性偏见
    - 肯定性的研究发现相比否定性的研究发现来说，更有可能被发表，从而影响我们对事实真相的判断
- 记忆性偏见
    - 回忆确实很神奇，但并不是优质数据的可靠来源。我们总是认为现在和过去是有逻辑联系的—有因才有果，这符合人类的思考方式。但问题是，当我们试图解释当前一些特别好或特别坏的结果时，我们的记忆便会出现“系统脆弱”的尴尬
- 幸存者偏见
    - 当样本中有一些或许多数据缺失，导致样本组成发生改变，从而影响分析的结果时，幸存者偏见就出现了
- 健康用户偏见
    - 下面有这样一个思维实验，假设公共卫生官员发布一个理论：所有家长都应该给他们刚出生的孩子穿上紫色睡衣睡觉，因为这会刺激孩子的大脑发育。20年后，纵向研究证实，穿紫色睡衣睡觉的孩子更有可能在人生中获得成功。举例说明，我们发现在哈佛大学学习的大一新生中，有高达98%的人在孩童时期（甚至到现在）都穿着紫色睡衣入睡；而在马萨诸塞州州立监狱系统内的犯人中，只有3%的人有穿紫色睡衣入睡的童年经历。紫色睡衣当然不会有什么作用，真正起作用的是给他们的孩子穿上紫色睡衣的家长。

# 九章 中心极限定理

中心极限定理是许多统计活动的“动力源泉”，这些活动存在着一个共同的特点，那就是使用样本对一个更大的数量对象进行推理

中心极限定理的核心要义就是，一个大型样本的正确抽样与其所代表的群体存在相似关系

当然，每个样本之间肯定会存在差异（比如前往马拉松起点的这么多辆客车，每辆客车乘客的组成都不可能完全相同），但是任一样本与整体之间存在巨大差异的概率是较低的

1.如果我们掌握了某个群体的具体信息，就能推理出从这个群体中正确抽取的随机样本的情况

2.如果我们掌握了某个正确抽取的样本的具体信息（平均数和标准差），就能对其所代表的群体做出令人惊讶的精确推理

3.如果我们掌握了某个样本的数据，以及某个群体的数据，就能推理出该样本是否就是该群体的样本之一

4.最后，如果我们已知两个样本的基本特性，就能推理出这两个样本是否取自同一个群体

样本数量越大，取样次数越多，样本平均值的分布就越接近一条正态分布曲线。（有一个经验是，样本数量必须达到30，中心极限定理才能保证成立）。这不难理解，样本所包含的数量越多，其平均值就越不容易受到随机偏差的干扰

平均值周围的聚集程度？为了避免混淆，我们首先需要对两个概念进行区分：标准差和标准误差。关于这两个概念，我们有必要记住的是：
1.标准差是用来衡量**群体中所有个体的离散性**。在之前的例子中，标准差衡量的是弗雷明汉心脏研究中所有参与者的体重分布，或马拉松比赛中所有参赛运动员的体重分布。
2.标准误差衡量的仅仅是**样本平均值的离散性**
3.现在就是将这两个概念合二为一的时刻：**标准误差就是所有样本平均值的标准差**

如果标准差本身的数值很大，那么标准误差的数值也不会小

如果样本数量变大，那么标准误差就会变小，这是因为大型样本受极端异常值的影响相对较小

# 十章 统计推断与假设检验

统计推断是一个让数据说话、让有价值的结论浮出水面的过程

统计推断正是我们之前已经讨论过的两个概念的合体：数据和概率（期间需要来自中心极限定理的一点儿帮助）

统计推断过程中最常使用的工具之一就是“假设检验”

例子

零假设：某种新药在预防疟疾方面并没有比安慰剂更加有效。
对立假设：该新药能够帮助预防疟疾。
数据：随机选取一个小组服用新药，另一个小组作为对照组服用安慰剂。一段时间过后，服用新药的小组的疟疾发病率要远低于对照组。如果该新药不具备任何疗效，那么出现这一结果的概率是非常低的。因此，我们推翻该新药没有疗效的零假设，承认其对立假设成立，即该新药能够帮助预防疟疾。

零假设和对立假设在逻辑方面是互补的，也就是说，如果其中一个假设为真，则另一个假设为假；如果我们推翻了其中一个假设，那就必须承认另一个假设

研究人员经常会提出一个零假设并希望有朝一日能够推翻它，虽然这听上去有违直觉

研究人员推翻零假设最常参考的“门槛”之一是5%，经常以十进位小数的形式表示为0.05。如果一个零假设想要为真，其支撑数据的结果必须至少达到0.05这个显著性水平，才能保证该假设具有意义

我们可以通过这一标准误差计算出两个样本来自同一个群体的概率。以下就是具体流程：
1.假如两个样本均抽取自同一个群体，那么最好的结果是它们的平均值之差为零。
2.中心极限定理告诉我们，在重复抽取的样本群里，两个平均值（样本平均值与群体平均值）之间的差将会呈正态分布
3.假如两个样本真的来自于同一个群体，那么有68%的概率，两个平均值之间的差小于一个标准误差；有约95%的概率，这个差会处于两个标准误差以内；有99.7%的概率会处于3个标准误差以内

Ⅰ型错误表示错误地推翻了一个零假设，可能直接看这些统计学术语不是那么直观，所以我们也称之为“假阳性”，下面就来解释一个为什么叫作“假阳性”

如果我们对所有新药的临床试验都要求0.001的显著性水平，那么将会极大地减少无效药物进入市场的可能性（因为错误推翻“药物没有比安慰剂更有疗效”的零假设的概率只有千分之一），但我们同时也面临着将有效药物拒之门外的风险，因为我们的准入门槛太高了，这就是统计学上的Ⅱ型错误，又称为“假阴性”

按常理，Ⅰ型错误（身体没有任何问题的“假阳性”）总是要优于Ⅱ型错误（癌症没有被诊断出来的“假阴性”）

平均值差异的标准误差

$$
\frac{\overline{x}-\overline{y}}{\sqrt{\frac{s_x^2}{n_x}+{s_y^2\over n_y}}}
$$

单尾/双尾假设检验

# 十一章 民意检测与误差幅度

民意调查和其他形式的抽样之间最根本的区别就在于，我们所关心的前者的样本数据不是平均数（如187磅），而是一个百分比（如47%的选民、0.47等）

对于任意一个随机抽取的样本而言，标准误差等于

$$
\sqrt{p*(1-p)\over n}
$$

其中p代表某个特定观点的回应者比例，（1-p）代表不同观点的回应者比例，n为样本中所有回应者的数量。而且由于n处于分母的位置，因此样本量越大，标准误差越小。而且当p与（1-p）的差距越来越大时，标准误差也会变得越来越小

电视台在播出新闻时如果要让自己的可信度提升，就必须扩大“误差幅度”，一旦这样做了，就意味着选举结果中不再有一个清晰的赢家了

民意测验就像是网恋，在对方所提供的信息里总是有那么一点儿“言不由衷”的成分。我们都知道，人都有撒谎的时候，尤其是当问题比较尴尬或敏感时

正是因为这些，一个民意测验先期准备得再充分、设计得再合理，也依然需要受访者的诚实回答。

当p 与1-p 接近50%时，相对小的抽样错误在民调结果中就会被放大为严重的绝对错误。而当p 或者1-p 接近于零时，就会出现相反的现象：即使是相对严重的抽样错误反映在民调结果中，也会变得微不足道

# 十二章 回归分析与线性关系

回归分析能够在控制其他因素的前提下，对某个具体变量与某个特定结果之间的关系进行量化。也就是说，我们能够在保持其他变量效果不变的情况下，将某个变量的效果分离出来，例如从事某项特定的工作。

回归分析与民意测验相类似。好消息是，在样本数量大、具有代表性且方法论成立的情况下，样本数据所呈现的相关性基本上与全体人口的现实情况差别不大

回归分析的强大能力表现在：将我们所关心的统计关联隔离出来，如工作中的支配力和心脏病，同时还不忘考虑其他可能会对这一相关关系产生影响的因素

最核心的一点是，回归分析寻找的是两个变量之间的最佳拟合线性关系

大致来看，符合身高和体重数据趋势的线有很多条，但我们如何知道哪一条才是“最佳”的？我们又如何定义“最佳”这两个字？回归分析的一个常用方法为最小二乘法（OLS），为什么OLS 能够得出最佳拟合线性关系，我们留给更高阶的课本去解释，这里的关键点在于，OLS 直线可以让所有数据的残差平方和为最小—别慌，这句话其实并没有那么难以理解。在我们的身高与体重数据组中，每一个数据都有一个残差，即距离回归线的垂直高度差，而对于那些直接落在回归线上的数据点，它们的残差则为零

OLS 公式中唯一不好理解的地方在于，在相加之前，我们需要将每个数据的残差平方（这就增加了那些离回归线特别远的数据，即极端异常值在结果中的比重）

对于任意一个回归系数，我们只需要关心3 件事情就行了：正负、大小和含义

正负。回归系数的正负揭示了自变量与因变量之间相关关系的方向

大小。自变量到底能对因变量产生多大的影响？这种影响会达到何种程度？

含义。统计结果到底是一个基于糟糕数据样本的错误，还是能够反映整个群体普遍真相的有意义的相关关系？

对于小型样本数据（例如20 位成年人而非“变化的一生”项目的3 000 人）来说，正态分布将不再是我们的“好朋友”。具体来说，假如我们对不同的小型样本进行回归分析，就不能指望这些回归系数会围绕着全体美国成年人身高和体重的真实情况呈正态分布，此时的分布情况我们称为“t 分布”（简单概括之，t 分布比起正态分布来说更加分散，因此左右两条“尾巴”的幅度更大）

随着样本容量的降低，每一次抽样得到的系数会分布得更加离散，因此分布曲线两端的“尾巴”相比起正态分布曲线来会显得“肥大”。如果样本容量减少到10，那么离散程度会更高，得到的“尾巴”会更“肥大”。t 分布实际上指的是各种不同容量样本的概率密度集体或“家族”，具体来说，样本中所包含的个体数量越多，那我们在分配适当的分布区间来评价研究结论时所拥有的“自由度”就越高

一个样本容量为10、解释变量个数为1 的基本回归分析的自由度为9。自由度越高，我们对该样本能够代表全体人口越有信心，其分布也会越“紧密”，随着自由度的增大，t 分布逐渐向正态分布靠拢。这也是为什么当我们在处理大型数据组时，可以直接使用正态分布曲线的基本特点来作为计算依据。

# 十三章 致命的回归错误

在进行回归分析时，需要记住的最重要的一点就是：尽量不要杀人。你甚至可以在你的电脑屏幕旁贴上一句话时刻提醒自己：“不要用你的研究杀人”。因为即使一些非常聪明的家伙有时候都免不了违反这条规定

以下就是让回归分析这一非凡的工具沦为“邪恶”工具的7 个最常见的错误。

- 用回归方程式来分析非线性关系
    - 我们无法用一个系数来准确概括高尔夫球课程和成绩之间的关系。对于上述关系来说，一个最佳的描述方式是：高尔夫球课程与我的挥球杆数之间存在着若干个不同的线性关系。
    - 只有当变量之间的关系为线性时，回归分析才可派上用场
- 相关关系并不等同于因果关系
    - 回归分析只能证明两个变量之间存在关系，至于是不是其中一个变量发生变化就一定能导致另一个变量也发生变化，仅凭数据我们无法给出证明
    - 事实上，一个并不十分严谨的回归分析也能在两个完全不相关的变量之间找到显著且有统计学意义的关系
- 因果倒置
    - 举例来说，解释GDP 增长时，在回归方程中加入失业率因素是不合适的，因为失业率很显然会受GDP 增长率的影响。或者换一个角度来看，通过回归分析，发现失业率的下降会促进GDP 的增长，这样的结论是可笑的、没有任何意义的，因为为了降低失业率，通常的做法是促进GDP 的增长
- 变量遗漏偏差
    - 当我们用回归方程式解释打高尔夫球与心脏病或其他疾病的关系时，如果将年龄因素排除在外，那“打高尔夫球”就会超出自身的解释作用，而相当于扮演了两个解释因素的角色：它不仅告诉我们打高尔夫球对心脏病的影响，而且还告诉我们年纪的增长对心脏病的影响（因为打高尔夫球的人通常比其他人要年老一些）
- 高度相关的解释变量（多元共线性）
    - 在一个回归方程式中，假如两个或两个以上解释变量彼此之间高度相关，那么回归分析的结果将有可能无法分清每一个变量与因变量之间的真实关系
    - 假设我们想要知道吸毒对SAT 考试分数的影响，我们会询问研究对象是否吸食过可卡因或海洛因（并且假设已经对其他许多变量进行了控制），并使用回归分析的方法，在控制其他变量的基础上（包括海洛因的使用），计算出可卡因对SAT 考试分数的影响；再同理计算出海洛因对考试的影响。
    但即使我们最后分别求出了海洛因和可卡因的回归系数，依然无法揭开真实的情况。方法论上的一大挑战在于，通常吸食可卡因的人同时也在吸食海洛因，只吸食过其中一种毒品的人的人数非常少，因此在计算两种毒品的独立影响时能用得上的数据量非常小，而且差异将不会很大
- 脱离数据进行推断
    - 和所有其他形式的统计推断一样，回归分析的目的是帮助我们更好地认识这个世界，发现能够适用于所有人口的规律。但需要强调的是，我们的结论仅仅是对与所分析样本相似的人口有效
- 数据矿（变量过多）
    - 假如变量过多，尤其当无关变量过多的时候，回归分析的结果就会被冲淡或稀释

本章精选的所有警示其实都可以浓缩为两个基本经验。
第一，设计一个好的回归方程式，想清楚应该考虑哪些变量、应该从哪里收集数据，一个好的方程式要比统计计算本身更加重要
第二，与绝大部分统计推断一样，回归分析始终以观察样本为立足点

# 十四章 项目评估与“反现实”

**随机控制实验**

安排实验组和对照组的一个最直接的方式就是—可能说出来有些多余—创造一个实验组和一个对照组。在使用这种方式时会遇到两大挑战

第一个挑战是，在很多时候是没有办法拿人做实验的，而且这一限制恐怕在短期内都无法解决

第二个挑战是，人作为实验对象要比实验室里的小白鼠变化得更多。

医学试验就是典型的随机控制实验。理想的情况是“双盲”的临床试验，这意味着无论是病人还是医生都不知道哪一组是治疗组，哪一组是对照组

**自然实验**

并不是所有人都有能力随随便便投资几百万美元来运行一个大型随机实验。一个更为经济的替代方案是寻找到一个自然实验，当某个事件自然而然地发生时，恰好营造出一个接近于随机、对照的实验环境

**非对等对照实验**

任何非随机分配都会产生偏见，至少是有存在偏见的可能性

但或许在实验组和对照组之间还有一些难以察觉的差异，正是这些差异影响了小组成员的分配和组成，从而产生跟现实有偏差的结论，这就是我们所说的“非对等对照”

**差分类差分实验**

观察原因和结果的一个最佳方式就是放手去做，然后看看会发生什么，因为这就是婴儿和小孩（有时候也包括成年人）认识世界的途径

“差分类差分”法可以通过两个步骤来明确某个介入因素的效果。首先，我们对某个群体接受某项介入因素或治疗之前和之后的数据进行比较，其次，我们将这些数据与另一个没有推出就业政策的同类县同期的失业率情况进行比较

前一个差分表示项目推广前后的失业率变化，后一个差分指的是两个县同期的失业率变化差异。另一个没有推广就业培训项目的县在研究过程中扮演的是对照组的角色，有利于我们更好地理解项目实施前后的数据变化，因为对照组会受到跟实验组一样的宏观经济的作用。最初我们认为就业培训项目一无是处（因为在项目实施之后失业率变得更高了），但是对照组为我们展示了更加糟糕的就业情况，因此通过综合比较和分析，就业培训项目的正面作用就显现出来了

**不连续分析实验**

实验组和对照组还存在一种设置方式，就是将那些刚好符合介入或治疗条件的对象，以及以毫厘之差错失治疗机会的对象进行比较。那些刚好超过或略微不足规定条件（如考试分数或最低家庭收入等）的个人，其实在许多重要方面与实验组里的个人相差无几，而一组对象接受治疗、另一组对象不接受治疗的人为划分其实本身就是非常任意的。因此，比较这两类对象可以为我们提供有关介入或治疗效果的有益参考。

对于任何一个项目评估来说，其目的都是为评价治疗或介入手段的效果提供某种“反现实”。在随机控制实验中，对照组就是“反现实”；但当对照实验不具有可行性或有违道德时，我们就需要寻求其他方式来模拟“反现实”。对这个世界的探索在很多时候就依赖于寻找“反现实”的聪明才智。

# 结束语 统计学能够帮忙解决的5个问题
